const fs = require('fs');
const path = require('path');
const { Pool } = require('pg');
require('dotenv').config();

const pool = new Pool({
  connectionString: process.env.DATABASE_PUBLIC_URL || process.env.DATABASE_URL,
  ssl: { rejectUnauthorized: false }
});

async function runMigrations() {
  try {
    console.log('üîß Starting migrations...\n');
    
    // Create migrations tracking table if it doesn't exist
    console.log('üìù Setting up migration tracking...');
    await pool.query(`
      CREATE TABLE IF NOT EXISTS migrations (
        id SERIAL PRIMARY KEY,
        name VARCHAR(255) NOT NULL UNIQUE,
        executed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      );
    `);
    console.log('‚úÖ Migration tracking table ready\n');

    const migrationsDir = path.join(__dirname, 'migrations');
    
    // Get all migration files (both .sql and .js)
    const sqlFiles = fs.readdirSync(migrationsDir)
      .filter(f => f.endsWith('.sql'))
      .sort();
    
    const jsFiles = fs.readdirSync(migrationsDir)
      .filter(f => f.endsWith('.js'))
      .sort();

    const allFiles = [...sqlFiles, ...jsFiles];
    console.log(`üìÅ Found ${allFiles.length} migration files (${sqlFiles.length} SQL, ${jsFiles.length} JavaScript)\n`);

    // Check which migrations have already been run
    const executedResult = await pool.query('SELECT name FROM migrations;');
    const executedMigrations = new Set(executedResult.rows.map(r => r.name));

    let migrationsRun = 0;

    // Run SQL migrations
    for (const file of sqlFiles) {
      if (executedMigrations.has(file)) {
        console.log(`‚è≠Ô∏è  Skipping ${file} (already executed)`);
        continue;
      }

      const filePath = path.join(migrationsDir, file);
      const sql = fs.readFileSync(filePath, 'utf8');
      
      console.log(`‚è≥ Running SQL: ${file}`);
      
      try {
        await pool.query(sql);
        // Record migration as executed
        await pool.query(
          'INSERT INTO migrations (name) VALUES ($1)',
          [file]
        );
        console.log(`‚úÖ Completed: ${file}\n`);
        migrationsRun++;
      } catch (err) {
        console.error(`‚ùå Error in ${file}: ${err.message}`);
        console.error('Continuing with other migrations...\n');
      }
    }

    // Run JavaScript migrations
    for (const file of jsFiles) {
      if (executedMigrations.has(file)) {
        console.log(`‚è≠Ô∏è  Skipping ${file} (already executed)`);
        continue;
      }

      const filePath = path.join(migrationsDir, file);
      console.log(`‚è≥ Running JS: ${file}`);
      
      try {
        const migration = require(filePath);
        
        if (typeof migration.runMigration === 'function') {
          await migration.runMigration();
        }
        
        // Record migration as executed
        await pool.query(
          'INSERT INTO migrations (name) VALUES ($1)',
          [file]
        );
        console.log(`‚úÖ Completed: ${file}\n`);
        migrationsRun++;
      } catch (err) {
        console.error(`‚ùå Error in ${file}: ${err.message}`);
        console.error('Continuing with other migrations...\n');
      }
    }
    
    console.log('‚ïê'.repeat(60));
    console.log('‚ú® All migrations completed!');
    console.log(`üìä Migrations run: ${migrationsRun}`);
    console.log(`‚è≠Ô∏è  Migrations skipped: ${allFiles.length - migrationsRun}`);
    console.log('‚ïê'.repeat(60));
    process.exit(0);
  } catch (err) {
    console.error('‚ùå Migration failed:', err);
    process.exit(1);
  } finally {
    await pool.end();
  }
}

runMigrations();
